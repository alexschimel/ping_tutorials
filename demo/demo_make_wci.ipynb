{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e09156-bd22-420c-b094-99edf94b3100",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use widgets as matplotlib backend\n",
    "%matplotlib widget\n",
    "\n",
    "# imports\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import os, sys\n",
    "from time import time\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "\n",
    "# import the file object for opening kongsberg files\n",
    "# Note: function and library naming to be discussed\n",
    "from themachinethatgoesping.echosounders import em3000 as em3000\n",
    "from themachinethatgoesping.echosounders import pingtools as pingtools\n",
    "from themachinethatgoesping.echosounders import ostream_redirect\n",
    "from themachinethatgoesping.algorithms import geoprocessing as gp\n",
    "import themachinethatgoesping.tools as ptools\n",
    "import themachinethatgoesping.navigation as pnav\n",
    "\n",
    "\n",
    "#simplify creating figures\n",
    "mpl.rcParams['figure.dpi'] = 100\n",
    "close_plots = True\n",
    "\n",
    "def create_figure(name, return_ax=True):\n",
    "    if close_plots: plt.close(name)\n",
    "    fig = plt.figure(name)\n",
    "    fig.suptitle = name\n",
    "\n",
    "    if return_ax:\n",
    "        return fig, fig.subplots()\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda2bfa0-b013-4dc3-ae7e-1646ea1f0502",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "background_map_path = \"/home/ssd/src/themachinethatgoesping/tutorials/test_data/map/210412_BELGIUM_BCP_DTM_20m_LAT.tiff\"\n",
    "#background_map_path = '/home/ssd/src/themachinethatgoesping/tutorials/usage/map/M143_EM710_StaircaseFlares_10-cube.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3d4cec-5e1e-4343-9415-61623102df95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# list of folders with kongsberg .all or .wcd files (subfolders will be scanned as well)\n",
    "\n",
    "folders=[]\n",
    "# folders.append(\"../test_data/kongsberg/\")\n",
    "# folders.append(\"/home/data/turbeams/koen campaign 2/\")\n",
    "# folders.append(\"/home/users/data/koen campaign 2\")\n",
    "# folders.append(\"/home/data/turbeams/TURBEAMS campaign 1/\")\n",
    "# folders.append(\"/home/users/data/TURBEAMS campaign 2/\")\n",
    "# folders.append(\"/home/data/GEOMAR/\")\n",
    "# folders.append(\"/home/data/test_data/\")\n",
    "# folders.append(\"/home/users/data/2023_8_TURBEAMS\")\n",
    "folders.append(\"/home/ssd/src/themachinethatgoesping/tutorials/test_data/kongsberg/\")\n",
    "\n",
    "files = []\n",
    "filenames = []\n",
    "for folder in folders:\n",
    "    for r,d,f in os.walk(folder):\n",
    "        for file in f:\n",
    "            if file.split('.')[-1] not in ['wcd','all','raw']:\n",
    "                continue\n",
    "            # if file.split('.')[-1] not in ['all']:\n",
    "            #    continue\n",
    "\n",
    "            if file.split(\"/\")[-1].split(\".\")[0] == \"9999\":\n",
    "                continue\n",
    "\n",
    "            if file in filenames:\n",
    "                continue\n",
    "\n",
    "            filenames.append(file)\n",
    "\n",
    "            filepath = r + '/' +file\n",
    "\n",
    "            if file.endswith('.wcd') or file.endswith('.all'):\n",
    "                files.append(filepath)\n",
    "            \n",
    "files.sort()\n",
    "file_name = files[0]\n",
    "print(\"files:      \", len(files))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9559102-2af9-4533-9664-e8591bb9dd35",
   "metadata": {},
   "source": [
    "Open all files\n",
    "The function \n",
    "Notes: \n",
    "1. em3000.FileEM3000_mapped(files) scanns and indexes all files and provides access to all files like a combined file stream\n",
    "2. If a .all and a .wcd files with the same name (one .all and one .wcd) are added, they will be matched to a single file\n",
    "3. It is not possible to add two .all or two .wcd with the same name, even if they are within different folders\n",
    "4. Note: if the files are not sorted in time, the datagram packages will not be sorted by time either, however it isi simple to sort the pings at a later stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3a6cdc-6163-451a-bcb4-406be3a3f762",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "try:\n",
    "    if True:\n",
    "        #index_path = 'm143.all_index'\n",
    "        #index_path = 'test.all_index'\n",
    "        index_path = 'belgium.all_index'\n",
    "        index = pickle.load(open(index_path,'rb'))\n",
    "        pass\n",
    "    else:\n",
    "        raise RuntimeError(\"reset index\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    index = {}\n",
    "\n",
    "print(len(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e90034-53c4-40ec-b620-6c04421ed56a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fm = em3000.FileEM3000_mapped(files, index, init=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9065ccd-5b50-4e68-a635-95406def6eb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd222530-fee4-44ff-9d6f-57ba5f8d10f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index.update(fm.get_cached_file_index())\n",
    "pickle.dump(index,open(index_path,'wb'))\n",
    "del index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5804664-abdb-40fb-b047-9803ce45ed59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import themachinethatgoesping.pingprocessing.watercolumn.make_image as mi\n",
    "import themachinethatgoesping.pingprocessing.watercolumn.helper.make_image_helper as mi_hlp\n",
    "reload(mi_hlp)\n",
    "reload(mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4d2db3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def group_dual_pings(pings):\n",
    "    transducers = set()\n",
    "    ping_groups = []\n",
    "    ping_group_map = {}\n",
    "    for ping in tqdm(pings):        \n",
    "        key = (ping.get_file_nr(),ping.get_file_ping_counter())\n",
    "        \n",
    "        if key not in ping_group_map:\n",
    "            ping_group_map[key] = len(ping_groups)\n",
    "            ping_groups.append(OrderedDict())\n",
    "            transducers.add(ping.get_channel_id())\n",
    "            \n",
    "        ping_groups[ping_group_map[key]][ping.get_channel_id()] = ping\n",
    "            \n",
    "    return ping_groups, transducers\n",
    "            \n",
    "ping_groups, transducers = group_dual_pings(fm.pings().get_sorted_by_time())\n",
    "print(f\"{len(ping_groups)}/{len(fm.pings())} ping groups\")\n",
    "print(transducers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa99aa3-7d27-4eb0-b809-17f58217e170",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ping_groups[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b1857e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class fake_tqdm(object):\n",
    "    def __init__(self, w_prg):\n",
    "        self.w_prg = w_prg\n",
    "        \n",
    "    def __call__(self, list_like):\n",
    "        self.list_like = list_like\n",
    "        self.list_iter = iter(list_like)\n",
    "        self.index = 0\n",
    "        self.total = len(list_like)\n",
    "        self.w_prg.max = self.total\n",
    "        self.w_prg.value = 0\n",
    "        return self\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        self.index += 1\n",
    "        self.w_prg.value = self.index\n",
    "        return next(self.list_iter)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.total\n",
    "    \n",
    "    def update(self):\n",
    "        self.index += 1\n",
    "        next(self.list_iter)\n",
    "        self.w_prg.value = self.index\n",
    "        \n",
    "    def close(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7931ade7-8829-44d1-88e0-0d50976b1d00",
   "metadata": {},
   "source": [
    "## Extract and plot navigation data\n",
    "1. The navigation interface is not yet ready, but we can already get the navigation of each transducer and put it into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce0e09e-d069-42d9-b134-cba1bed49e66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_pings = fm.pings().split_by_features([\"watercolumn\"])[0].get_sorted_by_time()\n",
    "\n",
    "#all_pings = all_pings.split_by_features([\"bottom\"])[0]\n",
    "print(len(all_pings),\"/\",len(fm.pings()))\n",
    "\n",
    "ping_containers = all_pings.split_by_time_diff(60 * 15)\n",
    "\n",
    "ping_containers = [p for p in ping_containers if len(p) > 100]\n",
    "\n",
    "for i,c in enumerate(ping_containers):\n",
    "    print(f\"{i}: {len(c)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505394d1-6435-438a-a24e-e836387fd9bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lat = []\n",
    "lon = []\n",
    "time = []\n",
    "nav_locations = defaultdict(list)\n",
    "for i, pings in enumerate(ping_containers):\n",
    "    for p in tqdm(pings):\n",
    "        try:\n",
    "            # we just use the location of the first transduce rhere\n",
    "            g = p.get_geolocation()\n",
    "            lat.append(g.latitude)\n",
    "            lon.append(g.longitude)\n",
    "            time.append(p.get_timestamp())\n",
    "            nav_locations[i].append([g.latitude,g.longitude])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511bce12-f2e4-40a8-90d3-280c01466bb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i,c in enumerate(ping_containers):\n",
    "    print(f\"{i}: {len(c)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89baf713-4f72-49df-8105-adb0e55e9958",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This code uses ipyleaflet for plotting the navigaiton data on background map (needs internet)\n",
    "# the code is thus unreleated to ping\n",
    "\n",
    "from ipyleaflet import Map, basemaps, basemap_to_tiles, AntPath, projections, Marker, AwesomeIcon\n",
    "from ipywidgets import Layout, HTML\n",
    "from matplotlib import colormaps,colors\n",
    "\n",
    "cmap = colormaps.get_cmap(\"tab20\")\n",
    "\n",
    "m = Map(\n",
    "    basemap=basemap_to_tiles(basemaps.Esri.NatGeoWorldMap),\n",
    "    center=(np.nanmedian(lat), np.nanmedian(lon)),\n",
    "    layout=Layout(width='80%', height='600px'),\n",
    "    zoom=9,\n",
    "    crs=projections.EPSG3857\n",
    ")\n",
    "\n",
    "for k,n in nav_locations.items():\n",
    "    ant_path = AntPath(\n",
    "        locations=n,\n",
    "        # dash_array=[1, 10],\n",
    "        # delay=1000,\n",
    "        color=colors.to_hex(cmap(k))\n",
    "        # pulse_color='#3f6fba'\n",
    "    )\n",
    "\n",
    "    m.add(ant_path)\n",
    "\n",
    "    icon = AwesomeIcon(\n",
    "        name='ship',\n",
    "        marker_color=\"white\",\n",
    "        icon_color=colors.to_hex(cmap(k)),\n",
    "        #spin=True\n",
    "        )\n",
    "    marker = Marker(\n",
    "        location = n[0],\n",
    "        icon=icon,\n",
    "        title=str(k)\n",
    "    )\n",
    "    message = HTML()\n",
    "    message.value = str(k)\n",
    "    marker.popup = message\n",
    "\n",
    "    m.add(marker)\n",
    "\n",
    "\n",
    "# marker = Marker(location = nav_locations[2][16764])\n",
    "# m.add(marker)\n",
    "# marker = Marker(location = nav_locations[2][17422])\n",
    "# m.add(marker)\n",
    "# marker = Marker(location = nav_locations[2][17730])\n",
    "# m.add(marker)\n",
    "try:\n",
    "    from localtileserver import get_leaflet_tile_layer, TileClient\n",
    "\n",
    "    client = TileClient(background_map_path)\n",
    "    t = get_leaflet_tile_layer(client,band=1,cmap=\"YlGnBu_r\")\n",
    "    m.add_layer(t)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(\"no background map\")\n",
    "\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4dcf3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "I = np.array(range(6,len(ping_containers),1))\n",
    "I = np.array(range(0,len(ping_containers),1))\n",
    "I = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41ee3ae-ee15-488e-9ff7-78ec2d4f1603",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pings=[]\n",
    "for i in I:\n",
    "    pings.extend([p for p in ping_containers[i].get_sorted_by_time()])\n",
    "for ping in tqdm(pings):\n",
    "   ping.load()\n",
    "\n",
    "ping_groups, transducers = group_dual_pings(pings)\n",
    "print(transducers, len(ping_groups), '/', len(pings))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b250812-e2e7-4077-b1e4-6201d14d52c6",
   "metadata": {},
   "source": [
    "## make Echogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd3e377-e05d-42e2-9b63-4a572add3b0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#set the beam angle range in degrees\n",
    "beam_angle_min = -20\n",
    "beam_angle_max = 20\n",
    "beam_step = 2\n",
    "sample_step = 1\n",
    "ping_step = 5\n",
    "ping_start = None\n",
    "ping_stop = None\n",
    "max_samples = 1700\n",
    "linear_mean = True\n",
    "\n",
    "\n",
    "#first loop, get statistics\n",
    "max_s_pnr = 0\n",
    "max_s = 0\n",
    "frequencies = {}\n",
    "\n",
    "#bss = pingtools.BeamSampleSelection(sample_step_ensemble=sample_step)\n",
    "pss = pingtools.PingSampleSelector()\n",
    "pss.select_beam_range_by_angles(beam_angle_min,beam_angle_max, beam_step)\n",
    "pss.select_sample_range_by_numbers(0, max_samples, sample_step)\n",
    "pss.set_sample_step(sample_step)\n",
    "\n",
    "for i,pg in enumerate(tqdm(ping_groups[ping_start:ping_stop:ping_step])):\n",
    "    for p in pg.values():\n",
    "        try:\n",
    "            sel = pss.apply_selection(p)\n",
    "\n",
    "            p.watercolumn.get_beam_crosstrack_angles(sel)\n",
    "            num_s = np.max(p.watercolumn.get_number_of_samples_per_beam(sel))\n",
    "\n",
    "            if num_s > max_s:\n",
    "                max_s = num_s\n",
    "                max_s_pnr = i\n",
    "                \n",
    "        except IndexError as e:\n",
    "            print(\"error:\",i,e,\"|\",type(e))\n",
    "        except ValueError as e:\n",
    "            print(\"error:\",i,e,\"|\",type(e))\n",
    "        except RuntimeError as e:\n",
    "            print(\"error:\",i,e,\"|\",type(e))\n",
    "\n",
    "if max_s > pss.get_max_sample_number():\n",
    "    max_s = pss.get_max_sample_number()\n",
    "\n",
    "\n",
    "data = np.empty((len(ping_groups[ping_start:ping_stop:ping_step]),max_s))\n",
    "data.fill(np.nan)\n",
    "index = 0\n",
    "\n",
    "\n",
    "with ostream_redirect():\n",
    "    for i,pg in enumerate(tqdm(ping_groups[ping_start:ping_stop:ping_step])):\n",
    "        #sel = pss.apply_selection(p)\n",
    "        A=[]\n",
    "        for p in pg.values():\n",
    "            try:\n",
    "                rt = gp.raytracers.RTConstantSVP(p.get_geolocation(),1450)\n",
    "                sel = pss.apply_selection(p)\n",
    "                r = p.raw_data\n",
    "                \n",
    "                            \n",
    "                samples = p.watercolumn.get_amplitudes(sel)\n",
    "                if linear_mean:\n",
    "                    samples = np.power(10,0.1*samples)\n",
    "                \n",
    "                index += 1\n",
    "\n",
    "                m = min(samples.shape[1], max_s)\n",
    "                a = data[i].copy()\n",
    "                            \n",
    "                a[:m] = np.nanmean(samples,axis=0)[:m]\n",
    "                A.append(a)\n",
    "        \n",
    "            except IndexError as e:\n",
    "                print(\"error:\",i,e,\"|\",type(e))\n",
    "            except ValueError as e:\n",
    "                print(\"error:\",i,e,\"|\",type(e))\n",
    "            except RuntimeError as e:\n",
    "                print(\"error:\",i,e,\"|\",type(e))\n",
    "                \n",
    "        data[i][:] = np.nanmean(A,axis=0)\n",
    "\n",
    "if linear_mean:\n",
    "    data = 10*np.log10(data)\n",
    "\n",
    "fig,ax = create_figure(\"test\")\n",
    "\n",
    "#ax.imshow(data.transpose(),aspect='auto',cmap='YlGnBu_r',vmin=-80, vmax = -30, interpolation='nearest')\n",
    "if ping_stop == None: ping_stop = len(ping_groups)\n",
    "if ping_start == None: ping_start = 0\n",
    "ax.imshow(data.transpose(),aspect='auto',cmap='YlGnBu_r',interpolation='nearest', extent = [-0.5+ping_start,ping_stop+0.5,data.shape[1]+0.5, -0.5])\n",
    "ax.set_ylim(data.shape[1],0)\n",
    "fig.set_tight_layout(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab36d7b",
   "metadata": {},
   "source": [
    "## make waterfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97868307",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_min_slant_range_sample(ping):\n",
    "    bs = ping.watercolumn.get_bottom_range_samples()\n",
    "    return np.nanmin(bs[bs > 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec058509",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#set the beam angle range in degrees\n",
    "beam_angle_min = -60\n",
    "beam_angle_max = 60\n",
    "beam_step = 1\n",
    "sample_step = 1\n",
    "ping_step = 50\n",
    "ping_start = None\n",
    "ping_stop = None\n",
    "linear_mean=True\n",
    "\n",
    "\n",
    "#first loop, get statistics\n",
    "max_b = 0\n",
    "frequencies = {}\n",
    "\n",
    "#bss = pingtools.BeamSampleSelection(sample_step_ensemble=sample_step)\n",
    "pss = pingtools.PingSampleSelector()\n",
    "pss.select_beam_range_by_angles(beam_angle_min,beam_angle_max, beam_step)\n",
    "pss.set_sample_step(sample_step)\n",
    "\n",
    "pss_left = pss.copy()\n",
    "pss_right = pss.copy()\n",
    "\n",
    "# pss_left.select_beam_range_by_angles(beam_angle_min,0, beam_step)\n",
    "# pss_right.select_beam_range_by_angles(0,beam_angle_max, beam_step)\n",
    "\n",
    "for i,pg in enumerate(tqdm(ping_groups[ping_start:ping_stop:ping_step])):\n",
    "    num_b = 0\n",
    "    for p in pg.values():\n",
    "        \n",
    "        if (len(pg.values()) > 1):\n",
    "            ba = p.watercolumn.get_beam_crosstrack_angles()\n",
    "            # detect left or right swath\n",
    "            if np.nanmean(ba) < 0: \n",
    "                sel = pss_left.apply_selection(p)\n",
    "            else:         \n",
    "                sel = pss_left.apply_selection(p)       \n",
    "        else:\n",
    "            sel = pss.apply_selection(p)\n",
    "\n",
    "        num_b += len(p.watercolumn.get_beam_crosstrack_angles(sel))\n",
    "            \n",
    "    max_b = max(max_b,num_b)\n",
    "                \n",
    "\n",
    "data = np.empty((len(ping_groups[ping_start:ping_stop:ping_step]),max_b))\n",
    "data.fill(np.nan)\n",
    "index = 0\n",
    "\n",
    "\n",
    "prg = tqdm(ping_groups[ping_start:ping_stop:ping_step])\n",
    "for pn,pg in enumerate(prg):\n",
    "    try:\n",
    "        first_bn=0\n",
    "        amp_left = None\n",
    "        amp_right = None\n",
    "        \n",
    "        for ping in pg.values():  \n",
    "            left=True\n",
    "            if (len(pg.values()) > 1):                \n",
    "                ba = ping.watercolumn.get_beam_crosstrack_angles()\n",
    "                # detect left or right swath\n",
    "                if np.nanmean(ba) < 0: \n",
    "                    sel = pss_left.apply_selection(ping)\n",
    "                    left=False\n",
    "                else: \n",
    "                    sel = pss_right.apply_selection(ping)\n",
    "            else:\n",
    "                sel = pss.apply_selection(ping)            \n",
    "            \n",
    "            min_slant = get_min_slant_range_sample(ping)\n",
    "            min_s = min_slant - 100\n",
    "            if min_s < 0:\n",
    "                min_s = 0\n",
    "\n",
    "            sel.set_first_sample_number_ensemble(min_s)\n",
    "            sel.set_last_sample_number_ensemble(min_slant-20)\n",
    "            #sel.set_first_sample_number_ensemble(min_slant)\n",
    "            #sel.set_last_sample_number_ensemble(min_slant+100)\n",
    "            \n",
    "            amp = ping.watercolumn.get_amplitudes(sel)\n",
    "            if linear_mean:\n",
    "                amp = np.power(10,0.1*amp)\n",
    "            amp = np.nanmean(amp,axis=1)\n",
    "            \n",
    "            if left:\n",
    "                amp_left = amp\n",
    "            else:\n",
    "                amp_right = amp\n",
    "                \n",
    "        \n",
    "        data[pn][:len(amp_left)] = amp_left\n",
    "        \n",
    "        if amp_right is not None:\n",
    "            data[pn][len(amp_left):len(amp_left)+len(amp_right)] = amp_right\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "if linear_mean:\n",
    "    data = 10*np.log10(data)\n",
    "\n",
    "fig,ax = create_figure(\"waterfall\")\n",
    "\n",
    "#ax.imshow(data.transpose(),aspect='auto',cmap='YlGnBu_r',vmin=-80, vmax = -30, interpolation='nearest')\n",
    "if ping_stop == None: ping_stop = len(ping_groups)\n",
    "if ping_start == None: ping_start = 0\n",
    "ax.imshow(data.transpose(),aspect='auto',cmap='YlGnBu_r',interpolation='nearest', extent = [-0.5+ping_start,ping_stop+0.5,data.shape[1]+0.5, -0.5])\n",
    "ax.set_ylim(data.shape[1],0)\n",
    "fig.set_tight_layout(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89306706",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    tmp_accumulator = 0\n",
    "    ax.axvline(0,color='r',alpha=0.5)\n",
    "    ax.text(0,0,str(0),rotation=90,verticalalignment='bottom',horizontalalignment='center')\n",
    "    for i in I:\n",
    "        pc = ping_containers[i]\n",
    "        tmp_accumulator += len(pc)/2\n",
    "        print(tmp_accumulator)\n",
    "        ax.axvline(tmp_accumulator,color='r',alpha=0.5)\n",
    "        ax.text(tmp_accumulator,0,str(i+1),rotation=-90,verticalalignment='bottom',horizontalalignment='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dacb33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "last_file_nr = -1\n",
    "for i,pg in enumerate(ping_groups):\n",
    "    for ping in pg.values():\n",
    "        if ping.get_file_nr() != last_file_nr:\n",
    "            ax.axvline(i,color='grey',alpha=0.3,linestyle='--', linewidth=0.5)\n",
    "            last_file_nr = ping.get_file_nr()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc46778b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig_wci, ax_wci = create_figure(\"wci\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adcda6b-4dfd-49a0-8b34-b03c469a0f6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ipywidgets import *\n",
    "from time import time\n",
    "\n",
    "#ping_groups, transducers = group_dual_pings(fm.pings().get_sorted_by_time())\n",
    "\n",
    "fig_wci.set_tight_layout(True)\n",
    "\n",
    "last_split_plot = 100\n",
    "\n",
    "#@widgets.interact\n",
    "#@debounce(0.1)\n",
    "def update(w):  \n",
    "    try:\n",
    "        if w_protect_stack.value:\n",
    "            if w['owner'] != w_wci_stack:\n",
    "                if float(w_text_execution_time.value) > 0.5:\n",
    "                    w_wci_stack.value = w_wci_stack.value * 0.5 / float(w_text_execution_time.value)\n",
    "        if w_wci_stack.value > 1:\n",
    "            w_wci.step = int(w_wci_stack.value/2)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    \n",
    "    w_text_num_total.value = str(int(w_text_num_total.value) +1)\n",
    "    w_text_num_active.value = str(int(w_text_num_active.value) +1)\n",
    "    \n",
    "    t = time()\n",
    "    global a, last_split_plot, ax_wci, fig_wci, ping1, ping2\n",
    "    a = w\n",
    "    #print(w)\n",
    "    wci_index = w_wci.value\n",
    "    wci_stack = w_wci_stack.value\n",
    "    wci_stack_step = w_wci_stack_step.value\n",
    "    cmin = w_cmin.value\n",
    "    cmax = w_cmax.value\n",
    "    aspect = w_aspect.value\n",
    "    hsize = w_hsize.value\n",
    "    heads = w_heads.value\n",
    "    interpolation = w_interpolation.value\n",
    "    maxz = w_z.value\n",
    "    from_bottom = w_from_bottom.value\n",
    "    linear_mean = w_linear_stack.value\n",
    "     \n",
    "    ping_group = ping_groups[wci_index]\n",
    "    \n",
    "    if wci_stack > 1:\n",
    "        max_index = wci_index+wci_stack\n",
    "        if max_index > len(ping_groups):\n",
    "            max_index = len(ping_groups)\n",
    "        pings = []\n",
    "        for pp in ping_groups[wci_index:max_index:wci_stack_step]:\n",
    "            for p in pp.values():\n",
    "                pings.append(p)\n",
    "                \n",
    "        #pings = pings[::2]\n",
    "    \n",
    "\n",
    "    try:\n",
    "        if wci_stack > 1:\n",
    "            wci,extent = mi.make_wci_stack(pings,hsize,progress_bar=progress_bar,linear_mean=linear_mean,from_bottom_xyz=from_bottom)\n",
    "            split_plot=False\n",
    "        elif len(ping_group) == 1:\n",
    "            ping = list(ping_group.values())[0]\n",
    "            split_plot=False\n",
    "            if heads == 'split_dual_rect':\n",
    "                wci = ping1.watercolumn.get_amplitudes()\n",
    "                extent = [0, ping.watercolumn.get_number_of_beams(),0, ping.watercolumn.get_number_of_samples_per_beam()[0]]\n",
    "            else:\n",
    "                wci,extent = mi.make_wci(ping,hsize,from_bottom_xyz=from_bottom)\n",
    "        else:        \n",
    "            ping1 = ping_group['TRX-2004']\n",
    "            ping2 = ping_group['TRX-2031']\n",
    "            if heads == 'blend_dual':\n",
    "                wci,extent = mi.make_wci_dual_head(ping1,ping2,hsize,from_bottom_xyz=from_bottom)\n",
    "                split_plot=False\n",
    "            if heads == 'blend_dual_inverw_wci_stackse':\n",
    "                wci,extent = mi.make_wci_dual_head(ping2,ping1,hsize,from_bottom_xyz=from_bottom)\n",
    "                split_plot=False\n",
    "            if heads == 'split_dual':\n",
    "                wci1,extent1 = mi.make_wci(ping1,hsize,from_bottom_xyz=from_bottom)\n",
    "                wci2,extent2 = mi.make_wci(ping2,hsize,from_bottom_xyz=from_bottom)\n",
    "                split_plot=True\n",
    "            if heads == 'split_dual_rect':\n",
    "                wci1 = ping1.watercolumn.get_amplitudes()\n",
    "                wci2 = ping2.watercolumn.get_amplitudes()\n",
    "                extent1 = [0, ping1.watercolumn.get_number_of_beams(),0, ping1.watercolumn.get_number_of_samples_per_beam()[0]]\n",
    "                extent2 = [0, ping2.watercolumn.get_number_of_beams(),0, ping2.watercolumn.get_number_of_samples_per_beam()[0]]\n",
    "                split_plot=True\n",
    "        # if heads == 'both':\n",
    "        #     wci1,extent1 = make_image(ping1,hsize,from_bottom=from_bottom)\n",
    "        #     wci2,extent2 = make_image(ping2,hsize,from_bottom=from_bottom)\n",
    "        if split_plot:\n",
    "            if last_split_plot != split_plot:\n",
    "                fig_wci.clear()\n",
    "                ax_wci = fig_wci.subplots(ncols=2)\n",
    "                last_split_plot = True\n",
    "                \n",
    "            ax_wci[0].clear()\n",
    "            ax_wci[1].clear()\n",
    "                \n",
    "            mapable = ax_wci[0].imshow(wci1.transpose(),aspect=aspect, extent = extent1, cmap='YlGnBu_r',vmin=cmin, vmax=cmax,interpolation=interpolation)\n",
    "            mapable = ax_wci[1].imshow(wci2.transpose(),aspect=aspect, extent = extent2, cmap='YlGnBu_r',vmin=cmin, vmax=cmax,interpolation=interpolation)\n",
    "            \n",
    "            if not heads == 'split_dual_rect':\n",
    "                if not maxz == -1:\n",
    "                    ax_wci[0].set_ylim(maxz,0)\n",
    "                    ax_wci[1].set_ylim(maxz,0)\n",
    "        else:\n",
    "            if last_split_plot != split_plot:\n",
    "                fig_wci.clear()\n",
    "                ax_wci = fig_wci.subplots(ncols=1)\n",
    "                last_split_plot = False\n",
    "            \n",
    "            ax_wci.clear()\n",
    "                \n",
    "            mapable = ax_wci.imshow(wci.transpose(),aspect=aspect, extent = extent, cmap='YlGnBu_r',vmin=cmin,vmax=cmax, interpolation=interpolation)\n",
    "            \n",
    "            if not maxz == -1:\n",
    "                ax_wci.set_ylim(maxz,0)\n",
    "                               \n",
    "        w_text_num_active.value = str(int(w_text_num_active.value) -1)\n",
    "        w_text_execution_time.value = str(round(time()-t,3))\n",
    "            \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        #pass\n",
    "        raise (e)\n",
    "\n",
    "\n",
    "w_z = FloatSlider(min=-1, max=50, step=1, value = -1)\n",
    "w_cmin = FloatSlider(min=-150, max=150, step=5, value = -50)\n",
    "w_cmax = FloatSlider(min=-150, max=150, step=5, value = 50)\n",
    "w_wci = IntSlider(min=0, max=len(ping_groups)-1, step=1, value =0)\n",
    "w_hsize = IntSlider(min=1, max=2048, step=1, value = 300)\n",
    "\n",
    "w_from_bottom = Checkbox(description=\"from bottom\", value=False)\n",
    "w_linear_stack = Checkbox(description=\"linear stack\", value=True)\n",
    "w_protect_stack = Checkbox(description=\"protect stacking time\", value=True)\n",
    "\n",
    "w_aspect = Dropdown(options=['auto', 'equal'], value='equal')\n",
    "w_heads = Dropdown(options=['blend_dual', 'blend_dual_inverse', 'split_dual', 'split_dual_rect'], value='blend_dual')\n",
    "w_interpolation = Dropdown(options=['antialiased', 'none', 'nearest', 'bilinear', 'bicubic', 'spline16', 'spline36', 'hanning', 'hamming', 'hermite', 'kaiser', 'quadric', 'catrom', 'gaussian', 'bessel', 'mitchell', 'sinc', 'lanczos', 'blackman'], value='nearest')\n",
    "w_wci_stack = IntText(\n",
    "    value=1,\n",
    "    description='stack:',\n",
    "    disabled=False\n",
    ")\n",
    "w_wci_stack_step = IntText(\n",
    "    value=1,\n",
    "    description='stack step:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "w_text_num_total = Text(\n",
    "    value='0',\n",
    "    placeholder='0',\n",
    "    description='Total executions:',\n",
    "    disabled=False   \n",
    ")\n",
    "w_text_num_active = Text(\n",
    "    value='0',\n",
    "    placeholder='0',\n",
    "    description='Active executions:',\n",
    "    disabled=False   \n",
    ")\n",
    "w_text_execution_time = Text(\n",
    "    value='0',\n",
    "    placeholder='0',\n",
    "    description='Time of last execution:',\n",
    "    disabled=False   \n",
    ")\n",
    "w_progress = IntProgress(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=10,\n",
    "    step=1,\n",
    "    description='Stacking:',\n",
    "    bar_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    orientation='horizontal'\n",
    ")\n",
    "progress_bar = fake_tqdm(w_progress)\n",
    "\n",
    "box_text = HBox([w_text_num_total,w_text_num_active,w_text_execution_time])\n",
    "box_options = HBox([w_aspect,w_heads,w_interpolation,w_wci_stack,w_wci_stack_step])\n",
    "box_check = HBox([w_from_bottom,w_linear_stack,w_protect_stack])\n",
    "\n",
    "w_z.observe(update, names=['value'])\n",
    "w_cmin.observe(update, names=['value'])\n",
    "w_cmax.observe(update, names=['value'])\n",
    "w_wci.observe(update, names=['value'])\n",
    "w_wci_stack.observe(update, names=['value'])\n",
    "w_wci_stack_step.observe(update, names=['value'])\n",
    "w_hsize.observe(update, names=['value'])\n",
    "w_aspect.observe(update, names=['value'])\n",
    "w_from_bottom.observe(update, names=['value'])\n",
    "w_linear_stack.observe(update, names=['value'])\n",
    "w_heads.observe(update, names=['value'])\n",
    "w_interpolation.observe(update, names=['value'])\n",
    "\n",
    "\n",
    "update(0)\n",
    "display(fig_wci.canvas,w_progress, box_text, box_options, box_check, w_z, w_cmin,w_cmax,w_wci,w_hsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c01456",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pings_ = []\n",
    "for p in tqdm(pings):\n",
    "    if p.has_bottom():\n",
    "        if p.has_watercolumn():\n",
    "            if p.watercolumn.has_bottom_range_samples():\n",
    "                pings_.append(p)\n",
    "                p.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b96003b-3d6d-46e8-99e1-dc492f51b767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7514410d-306f-4bb3-8ab2-fda7f401deec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "heaves = []\n",
    "ht = []\n",
    "for d in tqdm(fm.datagram_interface.datagrams(\"AttitudeDatagram\").get_sorted_by_time()):\n",
    "    if d.get_heading_sensor_is_active():\n",
    "        for a in d.attitudes():\n",
    "            heaves.append(a.get_heave_in_meters())\n",
    "            ht.append(a.get_time_in_seconds() + d.get_timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7035d1be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get rtk data\n",
    "tblock = 15 * 60\n",
    "z = []\n",
    "t = []\n",
    "z_block = []\n",
    "t_block = []\n",
    "z_buffer = []\n",
    "t_buffer = []\n",
    "for d in tqdm(fm.datagram_interface.datagrams(\"DepthOrHeightDatagram\").get_sorted_by_time()):\n",
    "    z.append(d.get_height_in_meters())\n",
    "    z_buffer.append(z[-1])\n",
    "    \n",
    "    t.append(d.get_timestamp())\n",
    "    t_buffer.append(t[-1])\n",
    "    \n",
    "    if t_buffer[-1] - t_buffer[0] > tblock:\n",
    "        z_block.append(np.median(z_buffer))\n",
    "        t_block.append(np.median(t_buffer))\n",
    "        z_buffer = []\n",
    "        t_buffer = []\n",
    "    \n",
    "    \n",
    "z_block.append(np.median(z_buffer))\n",
    "t_block.append(np.median(t_buffer))\n",
    "z_buffer = []\n",
    "t_buffer = []   \n",
    "\n",
    "z = np.array(z) - np.nanmin(z_block)\n",
    "z_block = np.array(z_block) - np.nanmin(z_block)\n",
    "\n",
    "rtki = ptools.vectorinterpolators.AkimaInterpolator(t_block,z_block)\n",
    "z_rtki = rtki(t)\n",
    "\n",
    "fig,ax = create_figure(\"height\")\n",
    "ax.plot(t,z,label=\"raw\")\n",
    "ax.plot(t_block,z_block,label=f\"block {tblock}s\")\n",
    "ax.plot(t,z_rtki,label=f\"Akima RTK {tblock}s\", c= 'black')\n",
    "ax.plot(ht,heaves,label=f\"heaves\", c= 'green')\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"time\")\n",
    "ax.set_ylabel(\"height [m]\")\n",
    "ax.grid(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f566cb33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_min_slant_range_sample(ping):\n",
    "    bs = ping.watercolumn.get_bottom_range_samples()\n",
    "    return np.nanmin(bs[bs > 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1499e7f-960a-42a0-825d-81853f2392d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GridData(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.XYZ = []\n",
    "        self.vals = []\n",
    "\n",
    "        self.times = []\n",
    "        self.pnr = []\n",
    "        self.la = []\n",
    "        self.lo = []\n",
    "        \n",
    "    def add_xyz(self, xyz):\n",
    "        self.XYZ.append(xyz)\n",
    "        \n",
    "    def add_amp(self,amp):\n",
    "        self.vals.extend(np.nanmean(amp,axis=1))\n",
    "        \n",
    "    def add_path(self, geo_ll, pnr, time):\n",
    "        self.la.append(geo_ll.latitude)\n",
    "        self.lo.append(geo_ll.longitude)\n",
    "        self.pnr.append(pnr)\n",
    "        self.times.append(time)\n",
    "        \n",
    "    def write_path(self,path):\n",
    "        with open(path,'w') as ofi:\n",
    "            for p,lat,lon,t in zip(self.pnr,self.la,self.lo,self.times):\n",
    "                ofi.write(f\"{lat}\\t{lon}\\t{p}\\n{t}\\t{ptools.timeconv.unixtime_to_datestring(t)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25abc12a",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import utm\n",
    "from themachinethatgoesping.gridding.forwardgridder import ForwardGridder\n",
    "import xarray\n",
    "import rioxarray\n",
    "import os\n",
    "import gc\n",
    "\n",
    "os.makedirs(\"tiles\",exist_ok=True)\n",
    "\n",
    "ping_step = 1\n",
    "resm = 1\n",
    "    \n",
    "vmin = np.nan\n",
    "vmax = np.nan\n",
    "\n",
    "pss = pingtools.PingSampleSelector()\n",
    "#pss.select_beam_range_by_angles(-40,40, 1)\n",
    "\n",
    "\n",
    "grid_data = []\n",
    "first_time = 0\n",
    "prg = tqdm(pings_[::ping_step])\n",
    "for pn,ping in enumerate(prg):\n",
    "    try:\n",
    "        sel = pss.apply_selection(ping)\n",
    "        min_slant = get_min_slant_range_sample(ping)\n",
    "        min_s = min_slant - 100\n",
    "        if min_s < 0:\n",
    "            min_s = 0\n",
    "\n",
    "        sel.set_first_sample_number_ensemble(min_s)\n",
    "        sel.set_last_sample_number_ensemble(min_slant-20)\n",
    "        sc = ping.get_sensor_configuration()\n",
    "        xyz, bottom_directions, bottom_direction_sample_numbers = mi_hlp.get_bottom_directions_wci(ping,sel)\n",
    "\n",
    "\n",
    "        sc.add_target(\"pos\",sc.get_position_source())\n",
    "        ping.set_sensor_configuration(sc)\n",
    "\n",
    "        geo_ll = ping.get_geolocation(\"pos\")\n",
    "        geo = pnav.datastructures.GeoLocationUTM(geo_ll)\n",
    "        if ping.get_timestamp()-first_time > 3600*6:\n",
    "            grid_data.append(GridData())\n",
    "            first_time = ping.get_timestamp()\n",
    "            prg.set_postfix_str(f\"images: {len(grid_data)}\")\n",
    "\n",
    "        #xyz = ping.bottom.get_xyz()\n",
    "        xyz.rotate(geo.yaw)\n",
    "        xyz.translate(geo.northing,geo.easting,\n",
    "                        -sc.get_waterline_offset() \n",
    "                        - rtki(ping.get_timestamp())\n",
    "                        )\n",
    "        grid_data[-1].add_xyz(xyz)\n",
    "\n",
    "        amp = np.power(10,0.1*ping.watercolumn.get_amplitudes(sel))\n",
    "        grid_data[-1].add_amp(amp)\n",
    "        \n",
    "        grid_data[-1].add_path(geo_ll, pn*ping_step, ping.get_timestamp())\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "prg = tqdm(grid_data)\n",
    "for gd in prg:        \n",
    "    prg.set_postfix_str(\"concat...\")\n",
    "    gd.XYZ = gd.XYZ[0].concat(gd.XYZ)\n",
    "\n",
    "    x = gd.XYZ.x\n",
    "    y = gd.XYZ.y\n",
    "    z = gd.XYZ.z\n",
    "\n",
    "    prg.set_postfix_str(\"to lat/lon...\")\n",
    "    #convert to lat/lon\n",
    "    lat, lon = gd.XYZ.to_latlon(geo.utm_zone, geo.northern_hemisphere)\n",
    "    fake_z = np.array([0 for _ in z])\n",
    "\n",
    "    lamin=np.nanmin([np.min(gd.la),lat.min()])\n",
    "    lamax=np.nanmax([np.max(gd.la),lat.max()])\n",
    "    lomin=np.nanmin([np.min(gd.lo),lon.min()])\n",
    "    lomax=np.nanmax([np.max(gd.lo),lon.max()])\n",
    "\n",
    "    prg.set_postfix_str(\"grid...\")\n",
    "    #compute res\n",
    "\n",
    "    x_ = np.array([x[0],x[0]+resm])\n",
    "    y_ = np.array([y[0],y[0]])\n",
    "    mi,ma = utm.to_latlon(y_,x_,geo.utm_zone,northern=geo.northern_hemisphere)\n",
    "    res = np.max([mi.max()-mi.min(),ma.max()-ma.min()])\n",
    "\n",
    "    gridder = ForwardGridder.from_data(res, lat,lon,fake_z)\n",
    "\n",
    "    #iv,iw = gridder.interpolate_weighted_mean(lat,lon,fake_z,z)\n",
    "    iv,iw = gridder.interpolate_weighted_mean(lat,lon,fake_z,gd.vals)\n",
    "    iv = iv[:,:,0]\n",
    "    iw = iw[:,:,0]\n",
    "    depth = iv / iw\n",
    "    del iv,iw\n",
    "    gc.collect()\n",
    "    extent = [gridder.border_ymin, gridder.border_ymax,gridder.border_xmin, gridder.border_xmax]\n",
    "\n",
    "\n",
    "    prg.set_postfix_str(\"max xarray...\")\n",
    "    coord = {\n",
    "    'y':np.flip(gridder.get_x_coordinates()),\n",
    "    #'y':gridder.get_x_coordinates(),\n",
    "    'x':gridder.get_y_coordinates()\n",
    "    }\n",
    "    del gridder\n",
    "    gc.collect()\n",
    "    depth = 10*np.log10(np.flip(depth,axis=0))\n",
    "\n",
    "    vmax = np.nanmax([vmax,np.nanmax(depth)])\n",
    "    vmin = np.nanmin([vmin,np.nanmin(depth)])\n",
    "\n",
    "    prg.set_postfix_str(\"write tiff\")\n",
    "\n",
    "    da = xarray.DataArray(depth,coord)\n",
    "    #da.rio.write_transform(a, inplace=True)\n",
    "    da.rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "    uid = np.random.random()\n",
    "    da.rio.to_raster(f\"tiles/amp-{np.min(gd.times)}-{i}-{uid}_raster.tiff\")\n",
    "    #del depth,iv,iw\n",
    "    gd.write_path(f\"tiles/path-{np.min(gd.times)}-{i}-{uid}_path.txt\")\n",
    "    \n",
    "    prg.set_postfix_str(\"done\")\n",
    "    \n",
    "    del depth\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8aabff-ed8f-4d45-a9e6-a4395ada2a70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import utm\n",
    "from themachinethatgoesping.gridding.forwardgridder import ForwardGridder\n",
    "import xarray\n",
    "import rioxarray\n",
    "import os\n",
    "import gc\n",
    "\n",
    "os.makedirs(\"tiles\",exist_ok=True)\n",
    "\n",
    "ping_step = 1\n",
    "resm = 1\n",
    "    \n",
    "        \n",
    "prg = tqdm(grid_data)\n",
    "for gd in prg:        \n",
    "    prg.set_postfix_str(\"concat...\")\n",
    "    #gd.XYZ = gd.XYZ[0].concat(gd.XYZ)\n",
    "\n",
    "    x = gd.XYZ.x\n",
    "    y = gd.XYZ.y\n",
    "    z = gd.XYZ.z\n",
    "\n",
    "    prg.set_postfix_str(\"to lat/lon...\")\n",
    "    #convert to lat/lon\n",
    "    lat, lon = gd.XYZ.to_latlon(geo.utm_zone, geo.northern_hemisphere)\n",
    "    fake_z = np.array([0 for _ in z])\n",
    "\n",
    "    lamin=np.nanmin([np.min(gd.la),lat.min()])\n",
    "    lamax=np.nanmax([np.max(gd.la),lat.max()])\n",
    "    lomin=np.nanmin([np.min(gd.lo),lon.min()])\n",
    "    lomax=np.nanmax([np.max(gd.lo),lon.max()])\n",
    "\n",
    "    prg.set_postfix_str(\"grid...\")\n",
    "    #compute res\n",
    "\n",
    "    x_ = np.array([x[0],x[0]+resm])\n",
    "    y_ = np.array([y[0],y[0]])\n",
    "    mi,ma = utm.to_latlon(y_,x_,geo.utm_zone,northern=geo.northern_hemisphere)\n",
    "    res = np.max([mi.max()-mi.min(),ma.max()-ma.min()])\n",
    "\n",
    "    gridder = ForwardGridder.from_data(res, lat,lon,fake_z)\n",
    "\n",
    "    #iv,iw = gridder.interpolate_weighted_mean(lat,lon,fake_z,z)\n",
    "    iv,iw = gridder.interpolate_weighted_mean(lat,lon,fake_z,gd.vals)\n",
    "    iv = iv[:,:,0]\n",
    "    iw = iw[:,:,0]\n",
    "    depth = iv / iw\n",
    "    del iv,iw\n",
    "    gc.collect()\n",
    "    extent = [gridder.border_ymin, gridder.border_ymax,gridder.border_xmin, gridder.border_xmax]\n",
    "\n",
    "\n",
    "    prg.set_postfix_str(\"max xarray...\")\n",
    "    coord = {\n",
    "    'y':np.flip(gridder.get_x_coordinates()),\n",
    "    #'y':gridder.get_x_coordinates(),\n",
    "    'x':gridder.get_y_coordinates()\n",
    "    }\n",
    "    del gridder\n",
    "    gc.collect()\n",
    "    depth = 10*np.log10(np.flip(depth,axis=0))\n",
    "\n",
    "    vmax = np.nanmax([vmax,np.nanmax(depth)])\n",
    "    vmin = np.nanmin([vmin,np.nanmin(depth)])\n",
    "\n",
    "    prg.set_postfix_str(\"write tiff\")\n",
    "\n",
    "    da = xarray.DataArray(depth,coord)\n",
    "    #da.rio.write_transform(a, inplace=True)\n",
    "    da.rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "    uid = np.random.random()\n",
    "    da.rio.to_raster(f\"tiles/amp-{np.min(gd.times)}-{i}-{uid}_raster.tiff\")\n",
    "    #del depth,iv,iw\n",
    "    gd.write_path(f\"tiles/path-{np.min(gd.times)}-{i}-{uid}_path.txt\")\n",
    "    \n",
    "    prg.set_postfix_str(\"done\")\n",
    "    \n",
    "    del depth\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35435d56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rasters = []\n",
    "xmin = np.nan\n",
    "xmax = np.nan\n",
    "ymin = np.nan\n",
    "ymax = np.nan\n",
    "for r,d,f in os.walk('tiles'):\n",
    "    for file in tqdm(f):\n",
    "        #if (file.endswith('.tiff') or file.endswith(\".tif\")) and not \"BELGIUM\" in file and \"m143\" in r:\n",
    "        if file.endswith('.tiff'):\n",
    "            fname = os.path.abspath(r+'/'+file)\n",
    "            rasters.append(os.path.abspath(fname))\n",
    "            \n",
    "            # xmin = np.nanmin([xmin,np.nanmin(da.x)])\n",
    "            # xmax = np.nanmax([xmax,np.nanmax(da.x)])\n",
    "            # ymin = np.nanmin([ymin,np.nanmin(da.y)])\n",
    "            # ymax = np.nanmax([ymax,np.nanmax(da.y)])\n",
    "    break\n",
    "        \n",
    "rasters.sort()\n",
    "\n",
    "# dx = xmax-xmin\n",
    "# dy = ymax-ymin\n",
    "\n",
    "# ax.set_xlim(xmin-0.1*dx,xmax+0.1*dx)\n",
    "# ax.set_ylim(ymin-0.1*dy,ymax+0.1*dy)\n",
    "\n",
    "for i,r in enumerate(rasters):\n",
    "   print(i,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae8daeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
